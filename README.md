# SFED-GEN2
Codes for paper "A Complementary Facial Representation Extracting Method based on Deep Learning"

# Abstract of the Paper
In this paper, a pair of 18-layered Convolutional Deconvolutional Networks (Conv-Deconv) is proposed to learn a bidirectional mapping between the emotional expressions and the neutral expression.
One network extracts the complementary facial representations from emotional faces.
The other network reconstructs the original faces from the extracted representations.
Two networks are mutually inverse functions.
The extracted complementary facial representations are used to reconstruct the original faces, generate new faces and interpolate new faces.
A new facial expression dataset called Large-scale Synthesized Facial Expression Dataset (LSFED) is presented.
The dataset contains 105,000 emotional faces of 15,000 subjects synthesized by computer graphics programme.
Good experiment results are obtained after evaluating our method on the LSFED dataset and the real-world RaFD dataset.



# Large-scale Synthesized Facial Expression Dataset (LSFED)

The LSFED is currently the largest facial expression dataset.
It contains 15,000 subjects of different racial, ages, genders, facial geometries and facial appearances.
Each subject has seven aligned facial images of different emotions (angry, disgust, fear, happy, neutral, sad and surprise) with a resolution of 64 $\times$ 64 pixels.
Totally, the LSFED has 105,000 (15,000 subjects $\times$ 7 emotions) aligned facial images.
The facial images are synthesized using the FaceGen Modeller software rather than captured from real faces.

Download: https://pan.baidu.com/s/1RWaudL2vsYmUaouxe2NiEA